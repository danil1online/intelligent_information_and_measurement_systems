# –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç–µ ‚Ññ4 
**–¢–µ–º–∞:** –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. 4 —á–∞—Å–∞  

---

## üéØ –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã  
–ò–∑—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR) ‚Äì WER (Word Error Rate) –∏ CER (Character Error Rate).

---

## üìå –ó–∞–¥–∞—á–∏  
- –û–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏ —Ñ–æ—Ä–º—É–ª–∞–º–∏ WER –∏ CER.
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π ASR-–∫–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ Python —Å –ø–æ–¥—Å—á—ë—Ç–æ–º –º–µ—Ç—Ä–∏–∫.
- –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å WER –∏ CER –¥–ª—è –≥–æ—Ç–æ–≤—ã—Ö —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.  
- –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤—ã–≤–æ–¥—ã.

---

## üìÅ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–µ—Ç–æ–¥—ã
- –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì Python 3.10.
- –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
  - [matplotlib](https://matplotlib.org/),
  - [PyTorch (torch, torchvision)](https://pytorch.org/),
  - [jiwer](https://github.com/jitsi/jiwer),
  - [SpeechRecognition](https://github.com/Uberi/speech_recognition#readme),
  - [Tensorflow](tensorflow.org),
  - [soundfile](https://github.com/bastibe/python-soundfile),
  - [librosa](https://librosa.org/doc/latest/index.html),
  - [transformers](https://huggingface.co/docs/transformers/index),
  - [openai-whisper](https://github.com/openai/whisper).
- –î–∞—Ç–∞—Å–µ—Ç—ã
  - [Mozilla Common Voice (—Ä—É—Å—Å–∫–∏–π), –≤—ã–±—Ä–∞—Ç—å ~100 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π](https://commonvoice.mozilla.org/ru)
–∏–ª–∏
  - [LibriSpeech ‚Äúdev-clean‚Äù (15‚Äì20 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)](https://www.openslr.org/12).

–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º LibriSpeech

---

## üìö –ö—Ä–∞—Ç–∫–∞—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è  

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (ASR) –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª –≤ —Ç–µ–∫—Å—Ç. –ö–ª—é—á–µ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ ‚Äì —à—É–º—ã, –∞–∫—Ü–µ–Ω—Ç—ã, –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è.

–ú–µ—Ç—Ä–∏–∫–∞ WER –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ª—é –æ—à–∏–±–æ–∫ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤. –ï—ë —Ñ–æ—Ä–º—É–ª–∞:

$$
  WER = \frac{S + D + I}{N},
$$

–≥–¥–µ ùëÜ ‚Äì –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ–Ω, ùê∑ ‚Äì —É–¥–∞–ª–µ–Ω–∏–π, ùêº ‚Äì –≤—Å—Ç–∞–≤–æ–∫, ùëÅ ‚Äì —á–∏—Å–ª–æ —Å–ª–æ–≤ –≤ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ.

–ú–µ—Ç—Ä–∏–∫–∞ CER –æ—Ç—Ä–∞–∂–∞–µ—Ç –æ—à–∏–±–∫–∏ –Ω–∞ —Å–∏–º–≤–æ–ª–∞—Ö:

$$
  CER = \frac{S_c + D_c + I_c}{N_c},
$$

–≥–¥–µ –∏–Ω–¥–µ–∫—Å—ã ùëê –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –ø–æ–¥—Å—á—ë—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤.

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã

0. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ [Jupyter-Hub-–ò–ò–°–¢-–ù–ü–ò](http://195.133.13.56:8000/) –∏–∑ [–ø–µ—Ä–≤–æ–π —Ä–∞–±–æ—Ç—ã](docs/lab_1_cv_metrics.md#%EF%B8%8F-–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-—Å—Ä–µ–¥—ã)
1. –°–æ–∑–¥–∞–π—Ç–µ –≤ –∫–æ—Ä–Ω–µ –¥–æ–º–∞—à–Ω–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ –∫–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –Ω–µ–≥–æ:
```bash

mkdir lab_asr && cd lab_asr

```
2. –°–æ–∑–¥–∞–π—Ç–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:
```bash

python3.10 -m venv venv
source venv/bin/activate

```

3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash

pip install --upgrade pip setuptools wheel cython
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install scikit-learn matplotlib tensorflow-cpu jiwer SpeechRecognition soundfile librosa transformers openai-whisper


```

4. (–í—ã–ø–æ–ª–Ω–µ–Ω–æ) –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```python

#!/usr/bin/env python3
# File: fetch_librispeech_subset.py

import os
import sys
import urllib.request
import tarfile
import subprocess

# 1) –ù–∞—Å—Ç—Ä–æ–π–∫–∏: URL –Ω–∞–±–æ—Ä–∞ –∏ —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
LIBRISPEECH_URL = "http://www.openslr.org/resources/12/dev-clean.tar.gz"
ARCHIVE_NAME   = "dev-clean.tar.gz"
MAX_SAMPLES    = 10    # —Å–∫–æ–ª—å–∫–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤–∑—è—Ç—å

# 2) –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
BASE_DIR       = os.path.abspath(os.path.dirname(__file__))
DATA_DIR       = os.path.join(BASE_DIR, "data")
AUDIO_DIR      = os.path.join(DATA_DIR, "audio")
TRANS_DIR      = os.path.join(DATA_DIR, "transcripts")

for d in (DATA_DIR, AUDIO_DIR, TRANS_DIR):
    os.makedirs(d, exist_ok=True)

# 3) –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
archive_path = os.path.join(BASE_DIR, ARCHIVE_NAME)
if not os.path.isfile(archive_path):
    print(f"Downloading {LIBRISPEECH_URL} ‚Ä¶")
    urllib.request.urlretrieve(LIBRISPEECH_URL, archive_path)
    print("Download complete.")

# 4) –û—Ç–∫—Ä—ã–≤–∞–µ–º tar.gz –∏ —Å–æ–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ .flac
print(f"Extracting up to {MAX_SAMPLES} audio files ‚Ä¶")
ids = []
with tarfile.open(archive_path, "r:gz") as tar:
    for member in tar.getmembers():
        if member.name.endswith(".flac") and len(ids) < MAX_SAMPLES:
            fname = os.path.basename(member.name)
            utt_id = os.path.splitext(fname)[0]
            ids.append(utt_id)

            # –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ FLAC –≤ —Ñ–∞–π–ª
            flac_bytes = tar.extractfile(member).read()
            flac_path  = os.path.join(AUDIO_DIR, f"{utt_id}.flac")
            with open(flac_path, "wb") as out_f:
                out_f.write(flac_bytes)
            print(f"  ‚úÖ {utt_id}.flac")

            # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV —á–µ—Ä–µ–∑ ffmpeg
            wav_path = os.path.join(AUDIO_DIR, f"{utt_id}.wav")
            try:
                subprocess.run(
                    ["ffmpeg", "-y", "-i", flac_path, wav_path],
                    check=True,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                print(f"  üîÑ {utt_id}.wav")
            except FileNotFoundError:
                sys.exit("ffmpeg not found. Please install ffmpeg and rerun.")
            except subprocess.CalledProcessError:
                print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {utt_id}.flac ‚Üí .wav")

# 5) –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
print("Extracting transcripts ‚Ä¶")
with tarfile.open(archive_path, "r:gz") as tar:
    for member in tar.getmembers():
        if member.name.endswith(".trans.txt"):
            for line in tar.extractfile(member).read().decode("utf-8").splitlines():
                utt_id, text = line.split(" ", 1)
                if utt_id in ids:
                    txt_path = os.path.join(TRANS_DIR, f"{utt_id}.txt")
                    with open(txt_path, "w", encoding="utf-8") as out_t:
                        out_t.write(text)
                    print(f"  üìù {utt_id}.txt")

print("\n–ì–æ—Ç–æ–≤–æ! –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫:")
print(f"  {AUDIO_DIR}/  ‚Äî audio FLAC + WAV")
print(f"  {TRANS_DIR}/ ‚Äî transcripts TXT")


```

**–í—ã—à–µ–ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º `jupyter`, –ø–æ—ç—Ç–æ–º—É –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –≤ –µ–≥–æ –¥–æ–º–∞—à–Ω–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ.**

---

## üß™ –ü—Ä–∏–º–µ—Ä—ã –∏ –∑–∞–¥–∞–Ω–∏—è 

### üß™ –ü—Ä–æ—Å—Ç–µ–π—à–µ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ

1. –í –ø–µ—Ä–≤–æ–π –ø—Ä–æ—Å—Ç–µ–π—à–µ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–¥—Å—á—ë—Ç WER –∏ CER –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö –≥–∏–ø–æ—Ç–µ–∑ –∏ —ç—Ç–∞–ª–æ–Ω–æ–≤. 

```python
#!/usr/bin/env python3
# file: compute_errors.py

import os
import sys
import time
import speech_recognition as sr
from jiwer import wer, cer
import matplotlib.pyplot as plt

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
BASE_DIR    = os.path.abspath("/home/jupyter/lab_asr/")
AUDIO_DIR   = os.path.join(BASE_DIR, "data", "audio")
TRANS_DIR   = os.path.join(BASE_DIR, "data", "transcripts")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è
recognizer = sr.Recognizer()

# –°–ø–∏—Å–∫–∏ –¥–ª—è —ç—Ç–∞–ª–æ–Ω–æ–≤ –∏ –≥–∏–ø–æ—Ç–µ–∑
refs, hyps, utt_ids = [], [], []

# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º WAV-—Ñ–∞–π–ª–∞–º
for fname in sorted(os.listdir(AUDIO_DIR)):
    if not fname.lower().endswith(".wav"):
        continue

    utt_id, _ = os.path.splitext(fname)
    wav_path  = os.path.join(AUDIO_DIR, fname)
    txt_path  = os.path.join(TRANS_DIR, f"{utt_id}.txt")

    if not os.path.exists(txt_path):
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {utt_id}: –Ω–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏", file=sys.stderr)
        continue

    # –ß–∏—Ç–∞–µ–º —ç—Ç–∞–ª–æ–Ω
    with open(txt_path, encoding="utf-8") as f:
        ref = f.read().strip()
    refs.append(ref)
    utt_ids.append(utt_id)

    # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —á–µ—Ä–µ–∑ Google Web API
    with sr.AudioFile(wav_path) as src:
        audio = recognizer.record(src)
    try:
        hyp = recognizer.recognize_google(audio, language="ru-RU")
    except sr.RequestError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ API –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ {utt_id}: {e}", file=sys.stderr)
        hyp = ""
    except sr.UnknownValueError:
        hyp = ""
    hyps.append(hyp)

    print(f"{utt_id}:")
    print(f"  REF: {ref}")
    print(f"  HYP: {hyp}\n")
    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
    time.sleep(0.5)

if not refs:
    sys.exit("–ù–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ WAV-—Ñ–∞–π–ª—ã –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.")

# –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É utterance
wers = [wer(r, h) for r, h in zip(refs, hyps)]
cers = [cer(r, h) for r, h in zip(refs, hyps)]

# –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
avg_wer = sum(wers) / len(wers)
avg_cer = sum(cers) / len(cers)

print("=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ===")
print(f"–°—Ä–µ–¥–Ω–∏–π WER: {avg_wer:.3f}")
print(f"–°—Ä–µ–¥–Ω–∏–π CER: {avg_cer:.3f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(5, 4))
plt.bar(["WER", "CER"], [avg_wer, avg_cer], color=["skyblue", "salmon"])
plt.ylim(0, max(avg_wer, avg_cer) * 1.2)
plt.ylabel("Error rate")
plt.title("–°—Ä–µ–¥–Ω–∏–µ WER –∏ CER")
plt.tight_layout()
plt.savefig("error_rates.png", dpi=150)
print("\n–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ error_rates.png")

```


–ó–∞–ø—É—Å–∫ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏:

```bash
python compute_errors.py
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ "–ø–ª–∞—á–µ–≤–Ω—ã–π" - –æ—à–∏–±–∫–∏ –∫—Ä–∞–π–Ω–µ –≤—ã—Å–æ–∫–∏:

```bash
python compute_errors.py
2277-149896-0005:
  REF: MANY LITTLE WRINKLES GATHERED BETWEEN HIS EYES AS HE CONTEMPLATED THIS AND HIS BROW MOISTENED
  HYP: 

2277-149896-0006:
  REF: HE COULD ARRANGE THAT SATISFACTORILY FOR CARRIE WOULD BE GLAD TO WAIT IF NECESSARY
  HYP: 

2277-149896-0012:
  REF: SHE HAD NOT BEEN ABLE TO GET AWAY THIS MORNING
  HYP: 

2277-149896-0015:
  REF: HE WENT IN AND EXAMINED HIS LETTERS BUT THERE WAS NOTHING FROM CARRIE
  HYP: 

2277-149896-0018:
  REF: HIS FIRST IMPULSE WAS TO WRITE BUT FOUR WORDS IN REPLY GO TO THE DEVIL
  HYP: is First impose ribe Forward in Reply go to the Java

2277-149896-0021:
  REF: WHAT WOULD SHE DO ABOUT THAT THE CONFOUNDED WRETCH
  HYP: 

2277-149896-0026:
  REF: THE LONG DRIZZLE HAD BEGUN PEDESTRIANS HAD TURNED UP COLLARS AND TROUSERS AT THE BOTTOM
  HYP: The Long restl Happy Gun 15

2277-149896-0027:
  REF: HURSTWOOD ALMOST EXCLAIMED OUT LOUD AT THE INSISTENCY OF THIS THING
  HYP: 

2277-149896-0033:
  REF: THEN HE RANG THE BELL NO ANSWER
  HYP: 

2277-149896-0034:
  REF: HE RANG AGAIN THIS TIME HARDER STILL NO ANSWER
  HYP: Heaven again the time Hunter Still no answer

=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ===
–°—Ä–µ–¥–Ω–∏–π WER: 1.000
–°—Ä–µ–¥–Ω–∏–π CER: 0.950

–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ error_rates.png
```


2. –í–æ –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Å—Ç–µ–π—à–µ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∞–∫–∂–µ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–π –º–æ–¥–µ–ª–∏ - —á–µ—Ä–µ–∑ SpeechRecognition + –º–µ—Ç—Ä–∏–∫–∏

```python

#!/usr/bin/env python3
# file: asr_pipeline.py

import os
import sys
import time
import speech_recognition as sr
from jiwer import wer, cer
import matplotlib.pyplot as plt

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
BASE_DIR   = os.path.abspath("/home/jupyter/lab_asr/")
AUDIO_DIR  = os.path.join(BASE_DIR, "data", "audio")
TRANS_DIR  = os.path.join(BASE_DIR, "data", "transcripts")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è
recognizer = sr.Recognizer()

def transcribe(wav_path: str) -> str:
    """
    –°—á–∏—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∏ –ø–µ—á–∞—Ç–∞–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ.
    """
    with sr.AudioFile(wav_path) as src:
        audio = recognizer.record(src)
    try:
        return recognizer.recognize_google(audio, language="ru-RU")
    except sr.UnknownValueError:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: {os.path.basename(wav_path)}", file=sys.stderr)
        return ""
    except sr.RequestError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ API –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ {os.path.basename(wav_path)}: {e}", file=sys.stderr)
        return ""

# –°–æ–±–∏—Ä–∞–µ–º —ç—Ç–∞–ª–æ–Ω—ã –∏ –≥–∏–ø–æ—Ç–µ–∑—ã
refs, hyps, utts = [], [], []
for fname in sorted(os.listdir(AUDIO_DIR)):
    if not fname.lower().endswith(".wav"):
        continue

    utt_id   = os.path.splitext(fname)[0]
    wav_path = os.path.join(AUDIO_DIR, fname)
    txt_path = os.path.join(TRANS_DIR, f"{utt_id}.txt")

    if not os.path.exists(txt_path):
        print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {utt_id}: –Ω–µ—Ç {utt_id}.txt", file=sys.stderr)
        continue

    # –≠—Ç–∞–ª–æ–Ω
    with open(txt_path, encoding="utf-8") as f:
        ref = f.read().strip()
    refs.append(ref)
    utts.append(utt_id)

    # –ì–∏–ø–æ—Ç–µ–∑–∞
    hyp = transcribe(wav_path)
    hyps.append(hyp)

    print(f"{utt_id}  |  REF: {ref}")
    print(f"         HYP: {hyp}\n")
    time.sleep(0.5)   # —á—Ç–æ–±—ã –Ω–µ –±–∏—Ç—å –ø–æ API —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ

if not refs:
    sys.exit("–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ .wav + .txt.")

# –ü–æ–¥—Å—á—ë—Ç WER –∏ CER
wers = [wer(r, h) for r, h in zip(refs, hyps)]
cers = [cer(r, h) for r, h in zip(refs, hyps)]
avg_wer = sum(wers) / len(wers)
avg_cer = sum(cers) / len(cers)

print("=== –ò—Ç–æ–≥–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è ===")
print(f"–°—Ä–µ–¥–Ω–∏–π WER: {avg_wer:.3f}")
print(f"–°—Ä–µ–¥–Ω–∏–π CER: {avg_cer:.3f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
plt.figure(figsize=(5,4))
plt.bar(["WER","CER"], [avg_wer, avg_cer], color=["skyblue","salmon"])
plt.ylim(0, max(avg_wer, avg_cer)*1.2)
plt.ylabel("Error rate")
plt.title("–°—Ä–µ–¥–Ω–∏–µ WER –∏ CER")
plt.tight_layout()
plt.savefig("error_rates.png")
print("\n–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: error_rates.png")

```

–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–∞–∫–∂–µ –∫—Ä–∞–π–Ω–µ –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã:

```bash

python asr_pipeline.py
‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0005.wav
2277-149896-0005  |  REF: MANY LITTLE WRINKLES GATHERED BETWEEN HIS EYES AS HE CONTEMPLATED THIS AND HIS BROW MOISTENED
         HYP: 

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0006.wav
2277-149896-0006  |  REF: HE COULD ARRANGE THAT SATISFACTORILY FOR CARRIE WOULD BE GLAD TO WAIT IF NECESSARY
         HYP: 

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0012.wav
2277-149896-0012  |  REF: SHE HAD NOT BEEN ABLE TO GET AWAY THIS MORNING
         HYP: 

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0015.wav
2277-149896-0015  |  REF: HE WENT IN AND EXAMINED HIS LETTERS BUT THERE WAS NOTHING FROM CARRIE
         HYP: 

2277-149896-0018  |  REF: HIS FIRST IMPULSE WAS TO WRITE BUT FOUR WORDS IN REPLY GO TO THE DEVIL
         HYP: is First impose ribe Forward in Reply go to the Java

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0021.wav
2277-149896-0021  |  REF: WHAT WOULD SHE DO ABOUT THAT THE CONFOUNDED WRETCH
         HYP: 

2277-149896-0026  |  REF: THE LONG DRIZZLE HAD BEGUN PEDESTRIANS HAD TURNED UP COLLARS AND TROUSERS AT THE BOTTOM
         HYP: The Long restl Happy Gun 15

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0027.wav
2277-149896-0027  |  REF: HURSTWOOD ALMOST EXCLAIMED OUT LOUD AT THE INSISTENCY OF THIS THING
         HYP: 

‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å: 2277-149896-0033.wav
2277-149896-0033  |  REF: THEN HE RANG THE BELL NO ANSWER
         HYP: 

2277-149896-0034  |  REF: HE RANG AGAIN THIS TIME HARDER STILL NO ANSWER
         HYP: Heaven again the time Hunter Still no answer

=== –ò—Ç–æ–≥–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è ===
–°—Ä–µ–¥–Ω–∏–π WER: 1.000
–°—Ä–µ–¥–Ω–∏–π CER: 0.950

–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: error_rates.png

```
WER=1.0 –∏ CER‚âà0.95 –Ω–∞ Google-API –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å LibriSpeech dev-clean ‚Äî —ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Google, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–∞—è –Ω–∞ –±—ã—Ç–æ–≤—É—é —Ä–µ—á—å, –∞ LibriSpeech —á–∏—Ç–∞–µ—Ç—Å—è –≤ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö —Å —á–µ—Ç–∫–æ–π –¥–∏–∫—Ü–∏–µ–π –∏ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏. 

–ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –∞–¥–µ–∫–≤–∞—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (–∏–ª–∏ –≤—Å–µ):
- –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω–æ–π —Ä–µ—á–∏ ¬´—á–∏—Ç–∫–∞¬ª
- –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∞—É–¥–∏–æ –ø–æ–¥ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: 16 kHz, –º–æ–Ω–æ, VAD-—Ç—Ä–∏–º–º–∏–Ω–≥, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –º–æ—â–Ω—ã–µ ASR-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: Wav2Vec2 –∏–ª–∏ Whisper

---

### üß™ –ü—Ä–∏–º–µ—Ä 2. –£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è. Wav2Vec2 (fairseq / HuggingFace)

–ù–∏–∂–µ –ø—Ä–∏–º–µ—Ä —Å–∫—Ä–∏–ø—Ç–∞ `hf_wav2vec2_asr.py`, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Wav2Vec2

```python

#!/usr/bin/env python3
# file: hf_wav2vec2_asr.py

import os
import torch
import soundfile as sf
from jiwer import wer, cer
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor

MODEL_ID = "facebook/wav2vec2-large-960h-lv60-self"
AUDIO_DIR = "/home/jupyter/lab_asr/data/audio"
TRANS_DIR = "/home/jupyter/lab_asr/data/transcripts"

# 1) –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)
model     = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to("cuda" if torch.cuda.is_available() else "cpu")

refs, hyps = [], []

for fn in sorted(os.listdir(AUDIO_DIR)):
    if not fn.endswith(".wav"): continue
    utt = os.path.splitext(fn)[0]
    wav, sr = sf.read(os.path.join(AUDIO_DIR, fn))
    # 2) –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    if sr != 16000:
        import librosa
        wav = librosa.resample(wav, orig_sr=sr, target_sr=16000)

    # 3) –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥: VAD-trim (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # wav, _ = librosa.effects.trim(wav, top_db=20)

    # 4) –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –≤—ã–≤–æ–¥ –ª–æ–≥–∏—Ç–æ–≤
    input_values = processor(wav, sampling_rate=16000, return_tensors="pt").input_values
    logits       = model(input_values.to(model.device)).logits
    pred_ids     = torch.argmax(logits, dim=-1)
    transcription= processor.batch_decode(pred_ids)[0].lower().strip()

    refs.append(open(os.path.join(TRANS_DIR, f"{utt}.txt"), encoding="utf-8").read().lower().strip())
    hyps.append(transcription)

    print(f"{utt}  |  HYP: {transcription}")

# 5) –ü–æ–¥—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫
print("WER:", wer(refs, hyps))
print("CER:", cer(refs, hyps))

```

–ó–∞–ø—É—Å–∫:

```bash

python hf_wav2vec2_asr.py

```

–†–µ–∑—É–ª—å—Ç–∞—Ç - —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π. –ú–æ–¥–µ–ª—å Wav2Vec2ForCTC (–∏–º–µ–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–º 1.26G) –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç:

```bash
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```
–Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–º–Ω–æ–≥–æ –ª—É—á—à–µ —Ä–∞–Ω–µ–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö:
```bash
WER: 0.01694915254237288
CER: 0.0062402496099844
```

---

### üß™ –ü—Ä–∏–º–µ—Ä 3. –£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è. Whisper (OpenAI)

–ù–∏–∂–µ –ø—Ä–∏–º–µ—Ä —Å–∫—Ä–∏–ø—Ç–∞ `whisper_asr.py`, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Whisper (—Ä–∞–∑–º–µ—Ä 139M)

```python

#!/usr/bin/env python3
# file: whisper_asr.py

import os
import whisper
from jiwer import wer, cer

model = whisper.load_model("base")  # –º–æ–∂–Ω–æ –≤–∑—è—Ç—å tiny, small, medium, large
AUDIO_DIR = "/home/jupyter/lab_asr/data/audio"
TRANS_DIR = "/home/jupyter/lab_asr/data/transcripts"

refs, hyps = [], []

for fn in sorted(os.listdir(AUDIO_DIR)):
    if not fn.endswith(".wav"): continue
    utt = os.path.splitext(fn)[0]
    result = model.transcribe(os.path.join(AUDIO_DIR, fn), language="en", fp16=False)
    hyps.append(result["text"].lower().strip())
    refs.append(open(os.path.join(TRANS_DIR, f"{utt}.txt"), encoding="utf-8").read().lower().strip())
    print(f"{utt}  |  HYP: {result['text']}")

print("WER:", wer(refs, hyps))
print("CER:", cer(refs, hyps))

```

–ó–∞–ø—É—Å–∫:

```bash

python whisper_asr.py

```

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã:
```bash

WER: 0.22033898305084745
CER: 0.06396255850234009
```

–ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:
|               | Wav2Vec2 | Whisper (OpenAI) |
|---------------|----------------------------|-----------------------------|
| –û–±—ä–µ–º –º–æ–¥–µ–ª–∏ | 1.26G | 139M |
| WER | 0.017 | 0.220 |
| –°ER | 0.006 | 0.064 |

---
### üìå –ó–∞–¥–∞–Ω–∏–µ –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã

–¢—Ä–µ–±—É–µ—Ç—Å—è:
1. –î–æ–ø–æ–ª–Ω–∏—Ç—å –∫–æ–Ω–≤–µ–π–µ—Ä —ç—Ç–∞–ø–æ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —à—É–º–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ librosa).
2. –°—Ä–∞–≤–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —á–∏—Å—Ç–æ–º –∏ –∑–∞—à—É–º–ª—ë–Ω–Ω–æ–º –∞—É–¥–∏–æ.
3. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –¥–ª–∏–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (–∫–æ—Ä–æ—Ç–∫–∏–µ vs –¥–ª–∏–Ω–Ω—ã–µ) –Ω–∞ WER/CER.

---

## üí° –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤—ã–∫–ª—é—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã python (–¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–ø–∞—Å—Ç—å –Ω–∞–¥–ø–∏—Å—å (venv) –≤ –Ω–∞—á–∞–ª–µ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏):

```bash

deactivate

```


## –í–æ–ø—Ä–æ—Å—ã
1. –ö–∞–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —à—É–º–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ WER –∏ CER?
2. –ö–∞–∫–∞—è –º–µ—Ç—Ä–∏–∫–∞ –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ —Ä–∞–∑–Ω—ã–º –≤–∏–¥–∞–º –æ—à–∏–±–æ–∫ ‚Äì WER –∏–ª–∏ CER?
3. –ù–∞—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –¥–ª–∏–Ω–∞—Ö –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤?
4. –ö–∞–∫–∏–µ —à–∞–≥–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–ª–∏ –Ω–∞–∏–±–æ–ª—å—à–∏–π –≤—ã–∏–≥—Ä—ã—à –ø–æ –∫–∞—á–µ—Å—Ç–≤—É?
5. –ö–∞–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –≤—ã –≤–∏–¥–∏—Ç–µ –∏ –∫–∞–∫ –∏—Ö –º–æ–∂–Ω–æ –ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å?




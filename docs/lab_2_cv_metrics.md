# –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç–µ ‚Ññ2 
**–¢–µ–º–∞:** –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. 4 —á–∞—Å–∞  

---

## üéØ –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã  
–ò–∑—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ ¬´–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –î–µ—Ç–µ–∫—Ü–∏—è¬ª.

---

## üìå –ó–∞–¥–∞—á–∏  
- –ò–∑—É—á–∏—Ç—å Intersection over Union (IoU). 
- –ò–∑—É—á–∏—Ç—å mean Average Precision (mAP).  
- –ò–∑—É—á–∏—Ç—å Dice Coefficient.

---

## üìÅ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–µ—Ç–æ–¥—ã
- –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì Python 3.10.
- –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
  -  [scikit-learn](https://scikit-learn.org/),
  -  [matplotlib](https://matplotlib.org/),
  -  [PyTorch (torch, torchvision)](https://pytorch.org/),
  -  [pydensecrf](https://github.com/lucasb-eyer/pydensecrf.git).
- –î–∞—Ç–∞—Å–µ—Ç ‚Äì [Penn-Fudan Pedestrian Detection and Segmentation (170 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π).](https://www.kaggle.com/datasets/psvishnu/pennfudan-database-for-pedestrian-detection-zip)

–î–∞—Ç–∞—Å–µ—Ç Penn-Fudan Dataset —Å–æ–¥–µ—Ä–∂–∏—Ç 170 —Ü–≤–µ—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–µ—à–µ—Ö–æ–¥–æ–≤ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (PNG) –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã—Ö —Ä–∞–º–æ–∫ (PNG).

–ö–∞—Ç–∞–ª–æ–≥:

```code
PennFudanPed/
‚îú‚îÄ‚îÄ PNGImages/
‚îÇ   ‚îú‚îÄ‚îÄ FudanPed00001.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ PedMasks/
    ‚îú‚îÄ‚îÄ FudanPed00001_mask.png
    ‚îî‚îÄ‚îÄ ...
```
---

## üìö –ö—Ä–∞—Ç–∫–∞—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è  

### üìö –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è

–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ (—Å–µ–≥–º–µ–Ω—Ç—ã), –∫–∞–∂–¥–∞—è –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –æ–±—ä–µ–∫—Ç—É –∏–ª–∏ —Ñ–æ–Ω—É.

–í –∑–∞–¥–∞—á–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–º—É –ø–∏–∫—Å–µ–ª—é –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ø–µ—à–µ—Ö–æ–¥¬ª, ¬´–¥–æ—Ä–æ–≥–∞¬ª, ¬´–∑–¥–∞–Ω–∏—è¬ª).

–í –¥–µ—Ç–µ–∫—Ü–∏–∏ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–º–∏ —Ä–∞–º–∫–∞–º–∏, –∞ –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ —Ç–æ—á–Ω–æ –æ—á–µ—Ä—Ç–∏—Ç—å —Ñ–æ—Ä–º—É –æ–±—ä–µ–∫—Ç–∞.

### üìö –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏

1. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –ü–æ—Ä–æ–≥–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (Thresholding): —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ —è—Ä–∫–æ—Å—Ç–∏.
- –ê–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, k-means): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–∏–∫—Å–µ–ª–µ–π –ø–æ —Ü–≤–µ—Ç—É –∏–ª–∏ —Ç–µ–∫—Å—Ç—É—Ä–µ.
- –ì—Ä–∞—Ñ–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã (Graph Cut, GrabCut): –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–∏—é —Ä–∞–∑–º–µ—Ç–∫–∏ –∑–∞ —Å—á—ë—Ç –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Ä–∞–∑—Ä–µ–∑–æ–≤.
2. –ì–ª—É–±–æ–∫–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏
- Fully Convolutional Network (FCN): —Å–≤—ë—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å –±–µ–∑ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—ë–≤, –≤—ã–¥–∞—ë—Ç –∫–∞—Ä—Ç—É –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–∏–∫—Å–µ–ª–µ–π.
- U-Net: –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å ¬´—Å–∫–∞—á–∫–∞–º–∏¬ª –º–µ–∂–¥—É –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–º –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–º –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü.
- DeepLab (v3+): –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∏–≤–Ω—ã–µ —Å–≤—ë—Ä—Ç–∫–∏ (atrous convolution) –∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∏—Ä–∞–º–∏–¥–∞–ª—å–Ω—ã–µ –ø—É–ª—ã (ASPP) –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

### üìö –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- –ú–∞—Å–∫–∏ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è –ø–æ –∫–ª–∞—Å—Å–∞–º.
- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ (–ø–æ–≤–æ—Ä–æ—Ç—ã, –º–∞—Å—à—Ç–∞–±, —Å–¥–≤–∏–≥–∏).
2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –æ–±—ã—á–Ω–æ —Å–æ—á–µ—Ç–∞–µ—Ç –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—é –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ä–º—ã (Dice, IoU-loss).
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ –∏–ª–∏ –µ–≥–æ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π (Adam, SGD —Å –º–æ–º–µ–Ω—Ç—É–º–æ–º).
3. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ü—Ä—è–º–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∏–∫—Å–µ–ª–µ–π.
- –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü (CRF, –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏) –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è ¬´—à—É–º–æ–≤¬ª –Ω–∞ –∫—Ä–∞—è—Ö.

### üìö –í–∞—Ä–∏–∞–Ω—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∏—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

| –¢–∏–ø —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ | –ó–∞–¥–∞—á–∞ | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|-----------------|----------------|-----------------------------|
| –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è | –†–∞–∑–º–µ—Ç–∫–∞ –ø–∏–∫—Å–µ–ª–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º | –ù–µ —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Ä–∞–∑–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ |
| Instance Segmention | –í—ã–¥–µ–ª–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ | –ù—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ–ª–æ–≤—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–∞—Å–∫–∏ |
| Panoptic Segmentation | –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏–∫–∏ –∏ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ | –ü–æ–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ –ø–∏–∫—Å–µ–ª–∏ –∏ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏ —Ñ–æ–Ω |

–ì–ª—É–±–∂–µ –ø–æ–Ω—è—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–∂–Ω–æ –∏–∑—É—á–∏–≤:
- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ([SegFormer](SegFormer), [SETR](https://github.com/fudan-zvg/SETR)).
- [–°–ª–∞–±–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –±–µ–∑ –ø–∏–∫—Å–µ–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏](https://arxiv.org/html/2310.13026v2).
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∞–º–æ—Å—É–ø–µ—Ä–≤–∏–∑–∏–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

### üìö –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç—Ä–∏–∫–∞—Ö

Intersection over Union (IoU) ‚Äì –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ –∏—Å—Ç–∏–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∫ –ø–ª–æ—â–∞–¥–∏ –∏—Ö –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.

mean Average Precision (mAP) ‚Äì —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å –ø–æ–¥ –∫—Ä–∏–≤–æ–π Precision‚ÄìRecall –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º –∏–ª–∏ –ø–æ —Ä–∞–∑–Ω—ã–º –ø–æ—Ä–æ–≥–∞–º IoU.

Dice Coefficient ‚Äì –º–µ—Ä–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–≤—É—Ö –±–∏–Ω–∞—Ä–Ω—ã—Ö –º–∞—Å–æ–∫:

$$
  Dice = 2 \cdot \frac{|A \cap B|}{|A| + |B|}
$$

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã

0. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ [Jupyter-Hub-–ò–ò–°–¢-–ù–ü–ò](http://195.133.13.56:8000/) –∏–∑ [–ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ä–∞–±–æ—Ç—ã](docs/lab_1_cv_metrics.md#%EF%B8%8F-–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-—Å—Ä–µ–¥—ã)
1. –°–æ–∑–¥–∞–π—Ç–µ –≤ –∫–æ—Ä–Ω–µ –¥–æ–º–∞—à–Ω–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ –∫–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –Ω–µ–≥–æ:
```bash

mkdir segmentation_detection_lab
cd segmentation_detection_lab

```
2. –°–æ–∑–¥–∞–π—Ç–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:
```bash

python3.10 -m venv venv
source venv/bin/activate

```

3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash

pip install --upgrade pip setuptools wheel cython
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install scikit-learn matplotlib numpy opencv-python segmentation-models-pytorch efficientnet_pytorch
export CPLUS_INCLUDE_PATH=/usr/include/eigen3:$CPLUS_INCLUDE_PATH
git clone https://github.com/lucasb-eyer/pydensecrf.git
cd pydensecrf
pip install .
cd ..

```

## üß™ –ü—Ä–∏–º–µ—Ä—ã –∏ –∑–∞–¥–∞–Ω–∏—è 

### üß™ –ü—Ä–æ—Å—Ç–µ–π—à–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è. –ü–æ–≤—Ç–æ—Ä—è—Ç—å –¥–∞–Ω–Ω—ã–µ —à–∞–≥–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è!

**–î–∞–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–≤–µ–¥–µ–Ω –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è. –û–Ω –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏ —Ä–∞–∑–º–µ—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ /home/jupyter/segmentation_detection_lab/data/PennFudanPed/. –û–¥–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—É–∂–µ —Å–¥–µ–ª–∞–Ω–æ) –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ. –ï—Å—Ç—å –µ—Å—Ç—å –∂–µ–ª–∞–Ω–∏–µ –µ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å, —Ç–æ —Å–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å `evaluate_metrics.py` (–ø–æ–∫–∞–∑–∞–Ω –ø–æ–¥ –æ—Å–æ–Ω–æ–≤–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º), –∞ –∑–∞—Ç–µ–º —É–∂–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ**

**–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞**
–í –ø—Ä–æ—Å—Ç–µ–π—à–µ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –Ω–µ –Ω–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö, –∞ –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç—ã–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –ø—Ä–∏—ë–º–æ–º ‚Äî –¥–∏–ª–∞—Ç–∞—Ü–∏–µ–π (—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º) –∏—Å—Ö–æ–¥–Ω–æ–π ‚Äú–∏–¥–µ–∞–ª—å–Ω–æ–π‚Äù –º–∞—Å–∫–∏.

–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∞

1. –ó–∞–≥—Ä—É–∑–∫–∞ —ç—Ç–∞–ª–æ–Ω–Ω–æ–π –º–∞—Å–∫–∏. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–∏—Ç–∞–µ—Ç—Å—è —Ñ–∞–π–ª –º–∞—Å–∫–∏ –∏–∑ –ø–∞–ø–∫–∏ PedMasks:
```python
mask_gt = cv2.imread(ds.masks[idx], cv2.IMREAD_GRAYSCALE) > 0
```

–ó–¥–µ—Å—å `mask_gt` ‚Äî –±—É–ª–µ–≤–∞ –º–∞—Ç—Ä–∏—Ü–∞, –≥–¥–µ True –æ–∑–Ω–∞—á–∞–µ—Ç –ø–∏–∫—Å–µ–ª—å –æ–±—ä–µ–∫—Ç–∞.

2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –º–∞—Å–∫–∏. –°–∫—Ä–∏–ø—Ç –º–æ–∂–Ω–æ –Ω–∞–∑–≤–∞—Ç—å `run_inference.py`
```python
#!/usr/bin/env python3
import os
import json
import cv2
import numpy as np
import torch
from torchvision import transforms as T
from torchvision.models.detection import maskrcnn_resnet50_fpn
from evaluate_metrics import PennFudanDataset  # –≤–∞—à –∫–ª–∞—Å—Å –∏–∑ evaluate_metrics.py

def main(data_root, pred_mask_dir, pred_boxes_path, device="cpu"):
    # 1) –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
    os.makedirs(pred_mask_dir, exist_ok=True)
    ds = PennFudanDataset(root=data_root)
    model = maskrcnn_resnet50_fpn(pretrained=True).to(device).eval()
    transform = T.Compose([T.ToTensor()])

    pred_boxes = {}

    for idx in range(len(ds)):
        img, _ = ds[idx]                          # img ‚Äî numpy RGB
        img_t = transform(img).to(device).unsqueeze(0)

        # 2) –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        with torch.no_grad():
            out = model(img_t)[0]

        boxes  = out["boxes"].cpu().numpy().tolist()
        scores = out["scores"].cpu().numpy().tolist()

        # 3) –°–æ–±–∏—Ä–∞–µ–º union-–º–∞—Å–∫—É –≤—Å–µ—Ö –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤
        masks = (out["masks"].cpu().numpy() > 0.5).squeeze(1)  # (N,H,W)
        if masks.ndim == 2:  # –µ—Å–ª–∏ –≤—Å–µ–≥–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç
            union = masks.astype(np.uint8)
        else:
            union = np.any(masks, axis=0).astype(np.uint8)

        # 4) –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Å–∫—É –∫–∞–∫ PNG (0 –∏–ª–∏ 255)
        mask_name = os.path.basename(ds.mask_paths[idx])
        mask_out  = (union * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(pred_mask_dir, mask_name), mask_out)

        # 5) –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON
        pred_boxes[str(idx)] = {
            "boxes":  boxes,
            "scores": scores
        }

    # 6) –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    with open(pred_boxes_path, "w") as f:
        json.dump(pred_boxes, f, indent=2)
    print("Inference done.")

if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument("--data-root",       required=True,
                   help="–ü—É—Ç—å –∫ PennFudanPed")
    p.add_argument("--pred-mask-dir",   required=True,
                   help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏")
    p.add_argument("--pred-boxes-json", required=True,
                   help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –±–æ–∫—Å—ã (JSON)")
    args = p.parse_args()

    main(args.data_root, args.pred_mask_dir, args.pred_boxes_json)

```
–ï–≥–æ –∑–∞–ø—É—Å–∫ –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω –æ—Ç –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è `jupyter` —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```bash

python run_inference.py \
  --data-root       ./data/PennFudanPed \
  --pred-mask-dir   ./data/PennFudanPed/pred_masks \
  --pred-boxes-json ./data/PennFudanPed/pred_boxes.json
```
–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ `/home/jupyter/segmentation_detection_lab/data/PennFudanPed/pred_masks` –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã PNG-–º–∞—Å–∫–∏:
  ![–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ](../images/Orig_seg.png) 
  ![–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏](../images/Seg_seg.png) 

–∞ –≤ `pred_boxes.json` ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```json

{
  "0": { "boxes": [[x1,y1,x2,y2],...], "scores": [s1, s2, ...] },
  "1": { ... }
}

```

3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫. –ù–∞ –æ—Å–Ω–æ–≤–µ `mask_gt` –∏ `mask_pred` —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è:
- Dice Coefficient ‚Äî –º–µ—Ä–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –¥–≤—É—Ö –±–∏–Ω–∞—Ä–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
- IoU –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã—Ö —Ä–∞–º–æ–∫, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ –º–∞—Å–æ–∫ (bounding boxes)
- Precision‚ÄìRecall –Ω–∞ –æ—Å–Ω–æ–≤–µ IoU –∫–∞–∫ ‚Äú–æ—Ü–µ–Ω–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏‚Äù –¥–µ—Ç–µ–∫—Ü–∏–∏

–ö–æ–¥ –ø—Ä–∏–º–µ—Ä–∞, –ø–æ–¥–≥–æ—Ç–æ–≤–ª–∏–≤–∞—é—â–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é `evaluate_metrics.py`:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import argparse
import json
import cv2
import numpy as np
import torch
from torch.utils.data import Dataset


class PennFudanDataset(Dataset):
    """
    –ü—Ä–æ—Å—Ç–æ–π Dataset –¥–ª—è Penn-Fudan Pedestrian
    –û–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
      root/PNGImages   ‚Äî rgb .png
      root/PedMasks    ‚Äî .png-–º–∞—Å–∫–∏
    –ü—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ self.img_paths –∏ self.mask_paths
    —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º.
    """
    def __init__(self, root, transforms=None):
        self.root = root
        self.transforms = transforms

        img_dir  = os.path.join(root, "PNGImages")
        mask_dir = os.path.join(root, "PedMasks")

        # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Å .png –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        imgs = sorted([
            fname for fname in os.listdir(img_dir)
            if fname.lower().endswith(".png")
               and os.path.isfile(os.path.join(img_dir,  fname))
        ])
        masks = sorted([
            fname for fname in os.listdir(mask_dir)
            if fname.lower().endswith(".png")
               and os.path.isfile(os.path.join(mask_dir, fname))
        ])

        self.img_paths  = [os.path.join(img_dir,  f) for f in imgs]
        self.mask_paths = [os.path.join(mask_dir, f) for f in masks]

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º RGB-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_path = self.img_paths[idx]
        img_bgr  = cv2.imread(img_path)
        if img_bgr is None:
            raise FileNotFoundError(f"Image not found or unreadable: {img_path}")
        img      = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Å–∫—É
        mask_path = self.mask_paths[idx]
        mask_gray = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask      = np.array(mask_gray, dtype=np.uint8)

        # –í—ã–¥–µ–ª—è–µ–º ID –æ–±—ä–µ–∫—Ç–æ–≤ (0 ‚Äî —Ñ–æ–Ω)
        obj_ids = np.unique(mask)
        obj_ids = obj_ids[obj_ids != 0]

        # –ë–∏–Ω–∞—Ä–Ω—ã–µ –º–∞—Å–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (N, H, W)
        masks = mask[None, ...] == obj_ids[:, None, None]

        # –ö–æ—Ä–æ–±–∫–∏ [xmin, ymin, xmax, ymax]
        boxes = []
        for m in masks:
            ys, xs = np.where(m)
            boxes.append([int(xs.min()), int(ys.min()), int(xs.max()), int(ys.max())])
        boxes = torch.as_tensor(boxes, dtype=torch.float32)

        labels   = torch.ones((len(boxes),), dtype=torch.int64)
        masks    = torch.as_tensor(masks, dtype=torch.uint8)
        image_id = torch.tensor([idx])
        area     = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd  = torch.zeros((len(boxes),), dtype=torch.int64)

        target = {
            "boxes": boxes,
            "labels": labels,
            "masks": masks,
            "image_id": image_id,
            "area": area,
            "iscrowd": iscrowd
        }

        if self.transforms:
            img = self.transforms(img)

        return img, target


def compute_mask_iou(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:
    inter = np.logical_and(pred_mask, gt_mask).sum()
    union = np.logical_or(pred_mask, gt_mask).sum()
    if union == 0:
        return 1.0 if inter == 0 else 0.0
    return float(inter) / union


def compute_mask_dice(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:
    inter = np.logical_and(pred_mask, gt_mask).sum()
    total = pred_mask.sum() + gt_mask.sum()
    if total == 0:
        return 1.0 if inter == 0 else 0.0
    return 2.0 * inter / total


def compute_box_iou(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])

    interW = max(0, xB - xA + 1)
    interH = max(0, yB - yA + 1)
    inter  = interW * interH

    areaA = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
    areaB = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)
    union = areaA + areaB - inter

    if union == 0:
        return 0.0
    return inter / union


def compute_map(predictions, ground_truths, iou_threshold=0.5):
    """
    mAP (11-point interpolation) –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞.
    predictions: —Å–ø–∏—Å–æ–∫ {"image_id": int, "boxes": [[...]], "scores": [...]}
    ground_truths: dict image_id -> list of gt boxes
    """
    all_preds = []
    total_gts = 0

    for item in predictions:
        img_id = item["image_id"]
        for b, s in zip(item["boxes"], item["scores"]):
            all_preds.append({"image_id": img_id, "box": b, "score": s})

    for img_id, boxes in ground_truths.items():
        total_gts += len(boxes)

    all_preds.sort(key=lambda x: x["score"], reverse=True)

    tp = np.zeros(len(all_preds))
    fp = np.zeros(len(all_preds))
    matched = {img_id: np.zeros(len(gt), dtype=bool)
               for img_id, gt in ground_truths.items()}

    for idx, pred in enumerate(all_preds):
        img_id, pbox = pred["image_id"], pred["box"]
        gts = ground_truths.get(img_id, [])
        ious = [compute_box_iou(pbox, gt) for gt in gts]
        if ious:
            best_idx = int(np.argmax(ious))
            if ious[best_idx] >= iou_threshold and not matched[img_id][best_idx]:
                tp[idx] = 1
                matched[img_id][best_idx] = True
            else:
                fp[idx] = 1
        else:
            fp[idx] = 1

    tp_cum = np.cumsum(tp)
    fp_cum = np.cumsum(fp)
    recalls  = tp_cum / total_gts
    precisions = tp_cum / (tp_cum + fp_cum + 1e-8)

    recall_levels = np.linspace(0, 1, 11)
    precisions_at_recall = [
        precisions[recalls >= rl].max() if np.any(recalls >= rl) else 0.0
        for rl in recall_levels
    ]
    return np.mean(precisions_at_recall)


def main(args):
    # 1) –î–∞—Ç–∞—Å–µ—Ç
    ds = PennFudanDataset(root=args.data_root)

    # 2) –ü—É—Ç–∏ –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
    pred_mask_dir   = args.pred_mask_dir
    pred_boxes_json = args.pred_boxes_json

    # 3) –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –±–æ–∫—Å—ã
    with open(pred_boxes_json, "r") as f:
        pred_boxes = json.load(f)

    ious, dices = [], []
    map_preds = []
    gt_boxes_dict = {}

    for idx in range(len(ds)):
        # GT
        _, target = ds[idx]
        gt_masks = target["masks"].numpy().astype(bool)
        gt_union = np.any(gt_masks, axis=0)
        gt_boxes = target["boxes"].numpy().tolist()
        gt_boxes_dict[idx] = gt_boxes

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Å–∫–∞
        mask_name = os.path.basename(ds.mask_paths[idx])
        pm_path   = os.path.join(pred_mask_dir, mask_name)
        pm_img    = cv2.imread(pm_path, cv2.IMREAD_GRAYSCALE)
        if pm_img is None:
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {pm_path}")
        pm_bin = pm_img > 0

        ious.append(compute_mask_iou(pm_bin, gt_union))
        dices.append(compute_mask_dice(pm_bin, gt_union))

        rec = pred_boxes.get(str(idx), {})
        map_preds.append({
            "image_id": idx,
            "boxes": rec.get("boxes", []),
            "scores": rec.get("scores", [])
        })

    mAP = compute_map(map_preds, gt_boxes_dict, iou_threshold=args.iou_thresh)

    print(f"IoU (mean):  {np.mean(ious):.4f}")
    print(f"Dice (mean): {np.mean(dices):.4f}")
    print(f"mAP@{args.iou_thresh:.2f}:   {mAP:.4f}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Evaluate IoU, Dice and mAP on Penn-Fudan dataset"
    )
    parser.add_argument(
        "--data-root", type=str, required=True,
        help="–ö–æ—Ä–µ–Ω—å PennFudanPed (—Å –ø–∞–ø–∫–∞–º–∏ PNGImages –∏ PedMasks)"
    )
    parser.add_argument(
        "--pred-mask-dir", type=str, required=True,
        help="–ü–∞–ø–∫–∞ —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –º–∞—Å–∫–∞–º–∏"
    )
    parser.add_argument(
        "--pred-boxes-json", type=str, required=True,
        help="JSON —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –±–æ–∫—Å–∞–º–∏ {image_id: {boxes: [...], scores: [...]}}"
    )
    parser.add_argument(
        "--iou-thresh", type=float, default=0.5,
        help="–ü–æ—Ä–æ–≥ IoU –¥–ª—è mAP"
    )
    args = parser.parse_args()

    main(args)

```

–ó–∞–ø—É—Å–∫ `evaluate_metrics.py` –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏:

```bash
python evaluate_metrics.py \
  --data-root       /home/jupyter/segmentation_detection_lab/data/PennFudanPed \
  --pred-mask-dir   /home/jupyter/segmentation_detection_lab/data/PennFudanPed/pred_masks \
  --pred-boxes-json /home/jupyter/segmentation_detection_lab/data/PennFudanPed/pred_boxes.json
```

### üìå –ó–∞–¥–∞–Ω–∏–µ –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã #1

–¢—Ä–µ–±—É–µ—Ç—Å—è:
1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ mAP –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –ø–æ—Ä–æ–≥–æ–≤ IoU (–æ—Ç 0.5 –¥–æ 0.95 —Å —à–∞–≥–æ–º 0.05).
2. –°—Ä–∞–≤–Ω–∏—Ç—å mAP –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–∞—Ö –∏ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.

–ó–∞–≥–æ—Ç–æ–≤–∫–∞ `task_map.py`:

```python
import os
import numpy as np
from sklearn.metrics import average_precision_score

# TODO: –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ compute_iou –∏ –∑–∞–≥—Ä—É–∑–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞

def compute_map_at_thresholds(gt_boxes, pred_boxes, iou_thresholds):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ AP –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞ IoU –∏–∑ iou_thresholds.
    gt_boxes –∏ pred_boxes ‚Äì —Å–ø–∏—Å–∫–∏ —Å–ø–∏—Å–∫–æ–≤ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
    """
    ap_values = []
    for thr in iou_thresholds:
        # TODO: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç—å IoU –º–∞—Ç—Ä–∏—Ü—É,
        # –∑–∞—Ç–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å TP/FP –ø–æ –ø—Ä–∞–≤–∏–ª—É IoU>=thr, —Å–æ–±—Ä–∞—Ç—å –º–µ—Ç–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∏
        # –∏ –≤—ã–∑–≤–∞—Ç—å average_precision_score
        ap = 0.0  # –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ
        ap_values.append(ap)
    return ap_values

def main():
    iou_thresholds = np.arange(0.5, 1.0, 0.05)
    # TODO: –∑–∞–≥—Ä—É–∑–∏—Ç—å gt_boxes –∏ pred_boxes
    gt_boxes = []     # —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤: [[box1, box2, ...], ...]
    pred_boxes = []   # —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç –ø–ª—é—Å –æ—Ü–µ–Ω–∫–∏ confidences
    
    ap_list = compute_map_at_thresholds(gt_boxes, pred_boxes, iou_thresholds)

    # TODO: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ iou_thresholds vs ap_list
    # –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª map_vs_iou.png

if __name__ == "__main__":
    main()
```

### üß™ –ü—Ä–∏–º–µ—Ä 2. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

–ù–∏–∂–µ –ø—Ä–∏–º–µ—Ä —Å–∫—Ä–∏–ø—Ç–∞ `segment_smp_compare.py`, –∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É `segmentation_models_pytorch` –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä (U-Net, FPN, DeepLabV3) —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞–º–∏.

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
os.environ['GLOG_minloglevel'] = '2'  # 0=INFO,1=WARNING,2=ERROR
import argparse

import torch
import numpy as np
import cv2

from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image

import segmentation_models_pytorch as smp

import math
import torch.nn.functional as F


class PennFudanSegDataset(Dataset):
    """
    Dataset: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç
      img [3,H,W] float32 ‚àà [0,1]
      gt_mask [H,W] uint8 {0,1}
    """
    def __init__(self, root):
        self.img_dir  = os.path.join(root, "PNGImages")
        self.mask_dir = os.path.join(root, "PedMasks")
        
        # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Å .png –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        self.imgs = sorted([
            fname for fname in os.listdir(self.img_dir)
            if fname.lower().endswith(".png")
               and os.path.isfile(os.path.join(self.img_dir,  fname))
        ])
        self.masks = sorted([
            fname for fname in os.listdir(self.mask_dir)
            if fname.lower().endswith(".png")
               and os.path.isfile(os.path.join(self.mask_dir, fname))
        ])

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path  = os.path.join(self.img_dir,  self.imgs[idx])
        mask_path = os.path.join(self.mask_dir, self.masks[idx])

        img = read_image(img_path).float() / 255.0    # [3,H,W]
        mask = read_image(mask_path)[0]               # [H,W], uint8 0..255
        gt_mask = (mask > 0).to(torch.uint8)         # {0,1}

        # –≤—ã—á–∏—Å–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥
        _, H, W = img.shape
        new_H = math.ceil(H / 32) * 32
        new_W = math.ceil(W / 32) * 32
        pad_h = new_H - H
        pad_w = new_W - W
        # pad = (pad_left, pad_right, pad_top, pad_bottom)
        pad = (0, pad_w, 0, pad_h)

        # –ø–∞–¥–¥–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Ü–≤–µ—Ç–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä)
        img = F.pad(img, pad, mode='constant', value=0.0)

        # –ø–∞–¥–¥–∏–º –º–∞—Å–∫—É: —Å–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–∏–º –∫–∞–Ω–∞–ª, –ø–æ—Ç–æ–º —É–±–µ—Ä—ë–º
        mask = F.pad(gt_mask.unsqueeze(0).float(), pad, mode='constant', value=0.0)
        gt_mask = (mask.squeeze(0) > 0).to(torch.uint8)

        return img, gt_mask, self.imgs[idx]


def compute_iou(a: np.ndarray, b: np.ndarray) -> float:
    inter = np.logical_and(a, b).sum()
    union = np.logical_or(a, b).sum()
    return float(inter / union) if union else 1.0


def compute_dice(a: np.ndarray, b: np.ndarray) -> float:
    inter = np.logical_and(a, b).sum()
    tot   = a.sum() + b.sum()
    return float(2*inter / tot) if tot else 1.0


def evaluate_model(model, loader, device):
    model.to(device).eval()
    ious, dices = [], []

    with torch.no_grad():
        for imgs, gt_masks, _ in loader:
            # imgs: [B,3,H,W], gt_masks: [B,H,W]
            imgs = imgs.to(device)

            # 1) –ø–æ–ª—É—á–∞–µ–º –≤—ã—Ö–æ–¥
            outs = model(imgs)

            # 2) –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –º–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict (–Ω–∞ –±—É–¥—É—â–µ–µ)
            if isinstance(outs, dict):
                outs = outs.get("out", outs)

            # 3) –ø—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º [B,H,W]
            if outs.ndim == 4:
                # [B,1,H,W] ‚Üí [B,H,W]
                probs = torch.sigmoid(outs)[:, 0, :, :].cpu().numpy()
            else:
                # [B,H,W]
                probs = torch.sigmoid(outs).cpu().numpy()

            # 4) –≤—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –±–∞—Ç—á–∞
            gts = gt_masks.numpy().astype(np.uint8)
            for pred_prob, gt in zip(probs, gts):
                pred_mask = (pred_prob > 0.5).astype(np.uint8)
                ious.append(compute_iou(pred_mask, gt))
                dices.append(compute_dice(pred_mask, gt))

    return float(np.mean(ious)), float(np.mean(dices))


def main(data_root, batch_size):
    device = "cpu"

    ds = PennFudanSegDataset(data_root)
    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)

    architectures = {
        "Unet-R34":  smp.Unet(
                         encoder_name="resnet34",
                         encoder_weights="imagenet",
                         in_channels=3,
                         classes=1
                     ),
        "FPN-R34":   smp.FPN(
                         encoder_name="resnet34",
                         encoder_weights="imagenet",
                         in_channels=3,
                         classes=1
                     ),
        "DeepLabV3": smp.DeepLabV3(
                         encoder_name="resnet34",
                         encoder_weights="imagenet",
                         in_channels=3,
                         classes=1
                     ),
    }

    print(f"Dataset size: {len(ds)}, batch_size={batch_size}\n")
    print("Architecture |  Mean IoU  | Mean Dice")
    print("---------------------------------------")
    for name, model in architectures.items():
        iou, dice = evaluate_model(model, loader, device)
        print(f"{name:12} |   {iou:.4f}   |   {dice:.4f}")


if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--data-root",  required=True,
                   help="PennFudanPed root (PNGImages + PedMasks)")
    p.add_argument("--batch-size", type=int, default=4)
    args = p.parse_args()
    main(args.data_root, args.batch_size)



```

–ó–∞–ø—É—Å–∫:

```bash

export GLOG_minloglevel=2
python segment_smp_compare.py --data-root /home/jupyter/segmentation_detection_lab/data/PennFudanPed --batch-size 1

```

---

## üí° –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤—ã–∫–ª—é—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã python (–¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–ø–∞—Å—Ç—å –Ω–∞–¥–ø–∏—Å—å (venv) –≤ –Ω–∞—á–∞–ª–µ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏):

```bash

deactivate

```


## –í–æ–ø—Ä–æ—Å—ã
1. –ö–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ IoU –∏ Dice –ø—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–ø–æ—Å–æ–±–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–∞—Å–∫–∏?
2. –í —á–µ–º –æ—Ç–ª–∏—á–∏–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è IoU –∏ Dice, –∫–æ–≥–¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç "—à—É–º—ã" –ø–æ –∫—Ä–∞—è–º?
3. –ü–æ—á–µ–º—É mAP (AP) –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ IoU?
4. –ö–∞–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞—Å—á—ë—Ç–∞ mAP –¥–µ–ª–∞—é—Ç –µ–≥–æ –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –Ω–∞ –º–Ω–æ–≥–æ–æ–±—ä–µ–∫—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö?
5. –ö–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –±–æ–ª—å—à–µ –≤—ã–∏–≥—Ä—ã–≤–∞—é—Ç –æ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Dice Coefficient –≤–º–µ—Å—Ç–æ IoU, –∏ –ø–æ—á–µ–º—É?
6. –ö–∞–∫ –ø–æ–≤–ª–∏—è–µ—Ç –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤ (—Ä–∞–∑–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞) –Ω–∞ mAP?

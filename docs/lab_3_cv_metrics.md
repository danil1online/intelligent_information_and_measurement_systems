# –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –∫ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ ‚Ññ3 
**–¢–µ–º–∞:** –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π  

---

## üéØ –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã  
–ò–∑—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ ¬´–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π¬ª –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ.

---

## üìå –ó–∞–¥–∞—á–∏  
- –ò–∑—É—á–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã –º–µ—Ç—Ä–∏–∫–∏ Inception Score (IS). 
- –ò–∑—É—á–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã –º–µ—Ç—Ä–∏–∫–∏ Fr√©chet Inception Distance (FID).

---

## üìÅ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–µ—Ç–æ–¥—ã
- –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì Python 3.10.
- –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: TensorFlow/Keras, scikit-learn, matplotlib, numpy, pillow, scipy
- –î–∞—Ç–∞—Å–µ—Ç: [MNIST](https://www.kaggle.com/datasets/hojjatk/mnist-dataset):
1. 60 000 –æ–±—É—á–∞—é—â–∏—Ö –∏ 10 000 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–æ–º 28√ó28
2. –ì—Ä–µ–π—Å–∫–µ–π–ª, –æ–¥–∏–Ω –∫–∞–Ω–∞–ª
3. –£–¥–æ–±–µ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ VAE –∏ –Ω–∞—á–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç—Ä–∏–∫

---

## üìö –ö—Ä–∞—Ç–∫–∞—è —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è  

### üìö –ó–∞–¥–∞—á–∞ ¬´–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π¬ª

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, —Å–ø–æ—Å–æ–±–Ω–æ–π —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å—Ö–æ–∂–∏–µ –ø–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Å –æ–±—É—á–∞—é—â–∏–º –Ω–∞–±–æ—Ä–æ–º. –ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–≤—Ç–æ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–æ–≤ (VAE), –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π (GAN) –∏–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã —Ç–∞–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª—å–Ω–æ, –Ω–æ –∏ —Å –ø–æ–º–æ—â—å—é —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.

### üìö Inception Score (IS)

Inception Score –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö —Å–µ—Ç–∏ Inception v3 –Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö. –í—ã—Å–æ–∫–∏–π IS –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è, –µ—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–µ—Ç–∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã (–Ω–∏–∑–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è —É—Å–ª–æ–≤–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è) –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã (–≤—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è).

–§–æ—Ä–º—É–ª–∞ IS:

$$
  IS = exp(E_{x} \cdot D_{KL} \cdot (p(y|x) \mathbin{||} p(y))
$$

### üìö Fr√©chet Inception Distance (FID)

FID –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–º–∏ –≥–∞—É—Å—Å–æ–≤—ã–º–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö —Å–µ—Ç—å—é Inception v3. –ß–µ–º –º–µ–Ω—å—à–µ FID, —Ç–µ–º –±–ª–∏–∂–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.

–§–æ—Ä–º—É–ª–∞ FID:

$$
  \text{FID} = \Vert \mu_r - \mu_g \Vert^2 + \mathrm{Tr} \left( C_r + C_g - 2 \cdot \left( C_r C_g \right)^{1/2} \right)
$$

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã

0. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ [Jupyter-Hub-–ò–ò–°–¢-–ù–ü–ò](http://195.133.13.56:8000/) –∏–∑ [–ø–µ—Ä–≤–æ–π —Ä–∞–±–æ—Ç—ã](docs/lab_1_cv_metrics.md#%EF%B8%8F-–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-—Å—Ä–µ–¥—ã)
1. –°–æ–∑–¥–∞–π—Ç–µ –≤ –∫–æ—Ä–Ω–µ –¥–æ–º–∞—à–Ω–µ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ –∫–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –Ω–µ–≥–æ:
```bash

mkdir image_gen_lab
cd image_gen_lab

```
2. –°–æ–∑–¥–∞–π—Ç–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:
```bash

python3.10 -m venv venv
source venv/bin/activate

```

3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash

pip install --upgrade pip
pip install tensorflow-cpu scikit-learn matplotlib numpy pillow scipy imageio
```

---

## üß™ –ü—Ä–∏–º–µ—Ä - –º–µ—Ç–æ–¥ VAE

### üß™ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–æ—Å—Ç—ã–º VAE –Ω–∞ MNIST

–ü–µ—Ä–≤—ã–º —ç—Ç–∞–ø–æ–º –ø—Ä–∏–º–µ—Ä–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–∫—Ä–∏–ø—Ç `vae_mnist.py` —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–∏—è –Ω–∞ mnist –≤ —Ç–µ—á–µ–Ω–∏–µ 10 —ç–ø–æ—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞—Ç–µ–º –±—É–¥–µ–º –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ 

```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt

from tensorflow.keras import layers, Model
import tensorflow as tf

def build_encoder(latent_dim=2):
    inputs = layers.Input(shape=(28,28,1))
    x = layers.Flatten()(inputs)
    x = layers.Dense(128, activation='relu')(x)
    z_mean    = layers.Dense(latent_dim, name='z_mean')(x)
    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)

    def sampling(args):
        mean, log_var = args
        eps = tf.random.normal(shape=tf.shape(mean))
        return mean + tf.exp(0.5 * log_var) * eps

    z = layers.Lambda(sampling)([z_mean, z_log_var])
    return Model(inputs, [z_mean, z_log_var, z], name='encoder')

def build_decoder(latent_dim=2):
    latent_inputs = layers.Input(shape=(latent_dim,))
    x = layers.Dense(128, activation='relu')(latent_inputs)
    x = layers.Dense(28*28, activation='sigmoid')(x)
    outputs = layers.Reshape((28,28,1))(x)
    return Model(latent_inputs, outputs, name='decoder')

class VAE(Model):
    def __init__(self, encoder, decoder, **kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.loss_tracker        = tf.keras.metrics.Mean(name="loss")
        self.recon_loss_tracker  = tf.keras.metrics.Mean(name="recon_loss")
        self.kl_loss_tracker     = tf.keras.metrics.Mean(name="kl_loss")

    @property
    def metrics(self):
        return [self.loss_tracker,
                self.recon_loss_tracker,
                self.kl_loss_tracker]

    def compile(self, optimizer, **kwargs):
        super().compile(**kwargs)
        self.optimizer = optimizer

    def train_step(self, data):
        if isinstance(data, tuple):
            data = data[0]

        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction      = self.decoder(z)

            x_flat   = tf.reshape(data,        [-1, 28*28])
            rec_flat = tf.reshape(reconstruction, [-1, 28*28])

            recon_loss = tf.reduce_mean(
                tf.keras.losses.binary_crossentropy(x_flat, rec_flat)
            ) * 28 * 28

            kl_loss = -0.5 * tf.reduce_mean(
                tf.reduce_sum(1 + z_log_var
                              - tf.square(z_mean)
                              - tf.exp(z_log_var),
                              axis=1)
            )

            total_loss = recon_loss + kl_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.loss_tracker.update_state(total_loss)
        self.recon_loss_tracker.update_state(recon_loss)
        self.kl_loss_tracker.update_state(kl_loss)

        return {
            "loss":       self.loss_tracker.result(),
            "recon_loss": self.recon_loss_tracker.result(),
            "kl_loss":    self.kl_loss_tracker.result(),
        }

def main(epochs=5, output_dir='output'):
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    (x_train, _), (_, _) = mnist.load_data()
    x_train = x_train.astype('float32') / 255.
    x_train = np.expand_dims(x_train, -1)
    #vae, encoder, decoder = build_vae()
    # 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    latent_dim = 2
    encoder = build_encoder(latent_dim)
    decoder = build_decoder(latent_dim)
    vae     = VAE(encoder, decoder)
    #vae.compile(optimizer='adam')
    # 3. –û–±—É—á–µ–Ω–∏–µ
    vae.compile(optimizer=tf.keras.optimizers.Adam())
    
    #vae.fit(x_train, x_train, epochs=epochs, batch_size=128)
    vae.fit(x_train,
            epochs=10,
            batch_size=128)
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ decoder'–∞ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
    os.makedirs(output_dir, exist_ok=True)
    decoder.save(os.path.join(output_dir, 'decoder.h5'))
    print(f"Decoder saved to {output_dir}/decoder.h5")
    # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤
    z_sample = np.random.normal(size=(16, 2))
    x_decoded = decoder.predict(z_sample)
    plt.figure(figsize=(4,4))
    for i in range(16):
        plt.subplot(4,4,i+1)
        plt.imshow(x_decoded[i].reshape(28,28), cmap='gray')
        plt.axis('off')
    plt.savefig(f'{output_dir}/vae_mnist.png')

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=5)
    parser.add_argument('--output-dir', type=str, default='output')
    args = parser.parse_args()
    main(args.epochs, args.output_dir)

```

–ó–∞–ø—É—Å–∫ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏:

```bash
python vae_mnist.py --epochs 10 --output-dir images
```

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ images –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –æ–¥–∏–Ω —Ñ–∞–π–ª `vae_mnist.png` - –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –µ—â–µ –æ–¥–∏–Ω —Ñ–∞–π–ª - –º–æ–¥–µ–ª—å (`decoder.h5`), –∫–æ—Ç–æ—Ä–∞—è —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞. 

### üß™ –°–æ–∑–¥–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∏–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Ç.–Ω. —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞. 

–î–ª—è –µ–µ —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Å–∫—Ä–∏–ø—Ç `generate_samples.py`

```python

import os
import numpy as np
from tensorflow.keras.models import load_model
import imageio

def main(decoder_path="images/decoder.h5",
         output_dir="images",
         n_samples=2000,
         latent_dim=2):
    os.makedirs(output_dir, exist_ok=True)
    decoder = load_model(decoder_path)

    # –ë–µ—Ä—ë–º N —Ç–æ—á–µ–∫ –∏–∑ N(0,1)
    z = np.random.normal(size=(n_samples, latent_dim))
    imgs = decoder.predict(z)  # shape (n_samples, 28,28,1)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    for i, img in enumerate(imgs):
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º 0‚Äì1 ‚Üí 0‚Äì255 –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ uint8
        arr = (img[:, :, 0] * 255).astype(np.uint8)
        imageio.imwrite(f"{output_dir}/sample_{i:05d}.png", arr)

    print(f"Saved {n_samples} images to {output_dir}")

if __name__ == "__main__":
    main()

```

–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç:

```bash

python generate_samples.py

```

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ, –≤ –ø–∞–ø–∫–µ images –¥–æ–ª–∂–Ω—ã –ø–æ—è–≤–∏—Ç—å—Å—è 2000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —á—Ç–æ –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è.

### üß™ –†–∞–∑–º–µ—â–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ mnist –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ

–°–∫—Ä–∏–ø, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–Ω–µ–µ –æ–±—É—á–∏–ª –º–æ–¥–µ–ª—å, —Ä–∞–±–æ—Ç–∞–ª —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º mnist, —Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã–º –≤ –û–ó–£. –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–º–µ—Ç—å —Ç–∞–∫–æ–π –¥–∞—Ç–∞—Å–µ—Ç, —Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã–π –≤ –æ–¥–Ω–æ–º –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä, `data/mnist_real`

```python

# prepare_real_mnist.py
import os
import imageio
import numpy as np
from tensorflow.keras.datasets import mnist

def main(output_dir="data/mnist_real"):
    (x_train, _), _ = mnist.load_data()
    os.makedirs(output_dir, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 60 000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    for idx, img in enumerate(x_train):
        # MNIST —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ 0‚Äì255, uint8
        imageio.imwrite(os.path.join(output_dir, f"{idx:05d}.png"), img)

    print(f"Saved {len(x_train)} images to {output_dir}")

if __name__ == "__main__":
    main()

```

–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ —Ç–∞–∫–∂–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç:

```bash

python prepare_real_mnist.py

```

### üß™ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ IS –∏ FID –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

–ò —Ç–µ–ø–µ—Ä—å –º—ã –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞—Å—á–µ—Ç—É –º–µ—Ç—Ä–∏–∫ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Å–∫—Ä–∏–ø—Ç  `eval_metrics.py`

```python

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from scipy.linalg import sqrtm
from PIL import Image
import glob

def load_images(path, size=(299,299), max_images=1000):
    files = glob.glob(os.path.join(path, '*.png'))[:max_images]
    imgs = []
    for f in files:
        img = Image.open(f).convert('RGB').resize(size)
        imgs.append(np.array(img))
    return np.array(imgs)

def calculate_inception_score(images, splits=10):
    model = InceptionV3(include_top=True, weights='imagenet', pooling='avg')
    images = preprocess_input(images.astype('float32'))
    preds = model.predict(images)
    p_y = np.mean(preds, axis=0)
    scores = []
    N = preds.shape[0] // splits
    for i in range(splits):
        part = preds[i*N:(i+1)*N]
        kl = part * (np.log(part+1e-10) - np.log(p_y+1e-10))
        scores.append(np.exp(np.sum(kl, axis=1).mean()))
    return float(np.mean(scores)), float(np.std(scores))

def calculate_fid(real, gen):
    model = InceptionV3(include_top=False, pooling='avg')
    act1 = model.predict(preprocess_input(real.astype('float32')))
    act2 = model.predict(preprocess_input(gen.astype('float32')))
    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)
    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)
    covmean = sqrtm(sigma1.dot(sigma2))
    if np.iscomplexobj(covmean):
        covmean = covmean.real
    return np.sum((mu1 - mu2)**2) + np.trace(sigma1 + sigma2 - 2*covmean)

def main(real_dir, gen_dir):
    real = load_images(real_dir)
    gen = load_images(gen_dir)
    is_mean, is_std = calculate_inception_score(gen)
    fid_value = calculate_fid(real, gen)
    print(f'Inception Score: {is_mean:.3f} ¬± {is_std:.3f}')
    print(f'FID: {fid_value:.3f}')

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--real', type=str, required=True)
    parser.add_argument('--gen', type=str, required=True)
    args = parser.parse_args()
    main(args.real, args.gen)


```

–ó–∞–ø—É—Å–∫ –¥–∞–Ω–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞:

```bash

python eval_metrics.py --real data/mnist_real --gen images

```

---

## üìå –ó–∞–¥–∞–Ω–∏—è –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã

1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å—Ç–æ–π GAN –∏ –æ—Ü–µ–Ω–∏—Ç—å –µ—ë IS –∏ FID.
2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ (—Å—Ä–∞–≤–Ω–∏—Ç—å IS/FID –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è—Ö).
3. –ü—Ä–æ–≤–µ—Å—Ç–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è MNIST –∏ –ø–æ–¥–Ω–∞–±–æ—Ä–æ–≤ CIFAR-10.

---

## üí° –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤—ã–∫–ª—é—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã python (–¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–ø–∞—Å—Ç—å –Ω–∞–¥–ø–∏—Å—å (venv) –≤ –Ω–∞—á–∞–ª–µ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏):

```bash

deactivate

```


## –í–æ–ø—Ä–æ—Å—ã
1. –ö–∞–∫ Inception Score –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π?
2. –í –∫–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö IS –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π?
3. –ü–æ—á–µ–º—É FID —Å—á–∏—Ç–∞–µ—Ç—Å—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–º, –∏ –∫–∞–∫–∏–µ –µ–≥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è?
4. –ö–∞–∫ –≤–ª–∏—è–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å FID?
5. –ö–∞–∫–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –≤–ª–∏—è—é—Ç –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è IS –∏ FID?
